{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix , classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import  PCA\n",
    "\n",
    "#import Classifier model\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "feature = iris.data\n",
    "label = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature,test_feature,train_label,test_label = train_test_split(feature,label,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_feature.shape)\n",
    "print(test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalizer(copy=True, norm='l2')\n",
    "\n",
    "train_feature,test_feature,train_label,test_label = train_test_split(feature,label,test_size=0.2,random_state=1)\n",
    "train_feature_A = normalize.fit_transform(train_feature)\n",
    "test_feature_A = normalize.transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "train_feature,test_feature,train_label,test_label = train_test_split(feature,label,test_size=0.2,random_state=1)\n",
    "train_feature_A = scaler.fit_transform(train_feature)\n",
    "test_feature_A = scaler.transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize2 = Normalizer(copy=True, norm='l2')\n",
    "\n",
    "train_B = normalize2.fit_transform(feature)\n",
    "train_feature_B,test_feature_B,train_label,test_label = train_test_split(train_B,label,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = StandardScaler()\n",
    "\n",
    "train_B = scaler2.fit_transform(feature)\n",
    "train_feature_B,test_feature_B,train_label,test_label = train_test_split(train_B,label,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B = preprocessing.scale(feature)\n",
    "train_feature_B,test_feature_B,train_label,test_label = train_test_split(train_B,label,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04622511,  2.34319467, -1.47902854, -1.31769898],\n",
       "       [-0.89033581, -1.24028061, -0.45900886, -0.15407273],\n",
       "       [ 0.91847283, -0.04578885,  0.33433978,  0.23380268],\n",
       "       [-0.52857408,  2.10429632, -1.42236078, -1.05911537],\n",
       "       [ 2.48610699,  1.86539796,  1.46769499,  1.00955351]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_A[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05250608,  2.16998818, -1.45390138, -1.3154443 ],\n",
       "       [-0.90068117, -1.28296331, -0.4308277 , -0.13075464],\n",
       "       [ 0.91683689, -0.13197948,  0.36489628,  0.26414192],\n",
       "       [-0.53717756,  1.93979142, -1.39706395, -1.05217993],\n",
       "       [ 2.4920192 ,  1.70959465,  1.50164482,  1.05393502]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_B[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize = Normalizer(copy=True, norm='l2')\n",
    "#pca = PCA(n_components=100)\n",
    "#model=Pipeline(steps=[('svc',svc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state = Seed)\n",
    "\n",
    "tuned_parameters_MLP = [{               \n",
    "'MLP__alpha': [0.0001,0.00001] ,\n",
    "'MLP__tol': [0.0001,0.00001]\n",
    "}] \n",
    "\n",
    "model = Pipeline(steps=[('MLP',MLP)]) #('normalize',normalize),\n",
    "clf = GridSearchCV(model, tuned_parameters_MLP, cv=10,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MLP',\n",
       "                                        MLPClassifier(activation='relu',\n",
       "                                                      alpha=0.0001,\n",
       "                                                      batch_size='auto',\n",
       "                                                      beta_1=0.9, beta_2=0.999,\n",
       "                                                      early_stopping=False,\n",
       "                                                      epsilon=1e-08,\n",
       "                                                      hidden_layer_sizes=(100,),\n",
       "                                                      learning_rate='constant',\n",
       "                                                      learning_rate_init=0.001,\n",
       "                                                      max_fun=15000,\n",
       "                                                      max_iter=200,\n",
       "                                                      momentum=0.9,\n",
       "                                                      n_iter_no_change=10,\n",
       "                                                      nesterovs_momentum=True,\n",
       "                                                      power_t=0.5,\n",
       "                                                      random_state=7,\n",
       "                                                      shuffle=True,\n",
       "                                                      solver='adam', tol=0.0001,\n",
       "                                                      validation_fraction=0.1,\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'MLP__alpha': [0.0001, 1e-05],\n",
       "                          'MLP__tol': [0.0001, 1e-05]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1_macro', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
    "\n",
    "clf.fit(train_feature, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.95      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(test_feature)\n",
    "print(classification_report(test_label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
